---
title: "LLMZip: Lossless Text Compression using Large Language Models"
date: 2025-07-03T15:27:17+06:00
image: "images/research/1_LLMZip.png"
authors: "C. S. K. Valmeekam, K. Narayanan, D. Kalathil, J.F. Chamberland, S. Shakkottai"
link:
  url: https://arxiv.org/abs/2306.04050
  display: arXiv Preprint
type: "research"
---

We show that English text is a lot more compressible than what was believed to be possible previously. Our lossless compression algorithm combines the prediction from modern large language models with arithmetic coding and compresses text to about 0.7~bits/character, outperforming state-of-the-art compressors like BSC and PAQ.
